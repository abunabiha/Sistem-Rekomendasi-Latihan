# -*- coding: utf-8 -*-
"""Sistem-Rekomendasi-Latihan

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kmtlQVpkvp6Vrod7k8fU1JZI9E7AHBIT

# Data Understanding

download dulu dataset dengan kode berikut
"""

!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00232/RCdata.zip

"""lakukan unzip file dengan menerapkan kode berikut."""

!unzip /content/RCdata.zip

"""Perhatikanlah, terdapat 9 file csv dan satu file README.

Kesembilan file tersebut dapat kita kategorikan menjadi 3, yaitu restaurant, consumers, dan user-item-rating.

mari kita baca data-data di atas dengan menggunakan fungsi pandas.read_csv. Implementasikan kode berikut.
"""

import pandas as pd

accepts = pd.read_csv('/content/chefmozaccepts.csv')
cuisine = pd.read_csv('/content/chefmozcuisine.csv')
hours = pd.read_csv('/content/chefmozhours4.csv')
parking = pd.read_csv('/content/chefmozparking.csv')
geo = pd.read_csv('/content/geoplaces2.csv', encoding = "ISO-8859-1")
usercuisine = pd.read_csv('/content/usercuisine.csv')
payment = pd.read_csv('/content/userpayment.csv')
profile = pd.read_csv('/content/userprofile.csv')
rating = pd.read_csv('/content/rating_final.csv')

print('Jumlah data pembayaran yang diterima restoran: ', len(accepts.placeID.unique()))
print('Jumlah data masakan pada restoran: ', len(cuisine.placeID.unique()))
print('Jumlah data waktu buka restoran: ', len(hours.placeID.unique()))
print('Jumlah data lokasi restoran: ', len(geo.placeID.unique()))
print('Jumlah data masakan pengguna: ', len(usercuisine.userID.unique()))
print('Jumlah data profil pengguna: ', len(profile.userID.unique()))
print('Jumlah data penilaian yang diberikan pengguna: ', len(rating.userID.unique()))
print('Jumlah data penilaian restoran: ', len(rating.placeID.unique()))

"""Datanya memang tidak terlalu banyak karena kita hanya mengambil sampel berdasarkan placeID dan UserID. Namun, kita nanti akan melihat bagaimana data yang sedikit tetapi berkualitas bisa tetap memberikan rekomendasi yang baik. Selanjutnya, mari kita melakukan eksplorasi terhadap data dengan teknik univariate exploratory data analysis.

# Univariate Exploratory Data Analysis

Accept Variabel

Pertama, mari kita eksplorasi variabel accepts, yaitu jenis pembayaran yang diterima pada restoran tertentu. Implementasikan kode berikut.
"""

accepts.info()

"""Berdasarkan output di atas, kita dapat mengetahui bahwa file accept.csv memiliki 1314 entri. Ingatlah juga, accepts termasuk ke dalam kategori data Restaurant. Oleh karena itu, terdapat dua variabel di sini, yaitu placeID dan Rpayment. PlaceID merupakan ID restoran, sedangkan Rpayment merupakan jenis pembayaran yang digunakan pada restoran.

Untuk melihat ada berapa banyak entri yang unik berdasarkan placeID dan jenis-jenis pembayaran unik yang diterima, jalankan kode berikut.
"""

print('Banyak data: ', len(accepts.placeID.unique()))
print('Jenis Pembayaran yang diterima: ', accepts.Rpayment.unique())

"""Terdapat 615 data restoran yang unik dengan 12 jenis pembayaran yang diterima antara lain:
‘cash’, ‘VISA’, ‘MasterCard-Eurocard’, 'American_Express', 'bank_debit_cards', 'checks', 'Discover', 'Carte_Blanche', 'Diners_Club', 'Visa', 'Japan_Credit_Bureau', dan 'gift_certificates'.

Perhatikanlah, dari sebelumnya 1314 entri, setelah difilter dengan fungsi unique() datanya menjadi sejumlah 615.

Cuisine Variable

Selanjutnya, mari kita eksplorasi variabel cuisine, yaitu jenis masakan yang tersedia di restoran. Mari kita lihat info variabel cuisine dengan menggunakan fungsi info().
"""

cuisine.info()

"""Untuk melihat jumlah tipe masakan (cuisine) dan nama-nama masakannya, mari kita kembali gunakan fungsi unique()."""

print('Banyak tipe masakan: ', len(cuisine.Rcuisine.unique()))
print('Tipe masakan: ', cuisine.Rcuisine.unique())

"""Terdapat 59 tipe masakan yang berbeda dengan nama masakan seperti terlihat pada output kode.

Perhatikanlah, jenis-jenis masakan di atas. Pada modul selanjutnya kita akan gunakan data cuisine ini untuk memprediksi top-N rekomendasi bagi pengguna.

Profile

Seperti yang telah dibahas sebelumnya, profile pengguna kadang diperlukan untuk memahami pola preferensi terhadap suatu item. Pertama, kita lihat terlebih dahulu berapa jumlah kolom dan baris pada variabel profile.
"""

print(profile.shape)

"""Selanjutnya, mari kita lihat fitur apa saja yang terdapat pada variabel profile. Implementasikan kode berikut."""

profile.head()

"""Menarik. Kita mendapatkan berbagai data mulai dari marital_status, birth_year, smoker, religion, budget, dll. Jika kita ingin membangun sistem rekomendasi yang lebih kompleks, mungkin kita perlu menyertakan fitur-fitur di atas pada model. Data profile ini berguna jika kita ingin membuat sistem rekomendasi berdasarkan demografi atau kondisi sosial pengguna. Namun, untuk studi kasus kali ini, kita tidak akan menggunakan data profile pada model.

Pada latihan dengan content-based filtering nanti, data yang dibutuhkan adalah nama restoran dan cuisine. Kita akan menghitung kesamaan (similarity) cuisine dan nama restoran kemudian membuat rekomendasi berdasarkan kesamaan ini. Data-data ini dibutuhkan saat kita membuat sistem rekomendasi dengan teknik lain, misalnya, teknik yang melibatkan demografi.

Rating

Selanjutnya, mari kita eksplorasi data yang akan kita gunakan pada model yaitu data rating. Pertama, kita lihat seperti apa data pada variabel rating dengan fungsi head()

Dari fungsi rating.head(), kita dapat mengetahui bahwa data rating terdiri dari 5 kolom dengan tiga kategori rating. Kolom-kolom tersebut antara lain:

userID, merupakan identitas pengguna.
placeID, merupakan identitas restoran.
Rating, merupakan data rating untuk restoran.
Food_rating, merupakan data rating untuk makanan atau masakan di restoran tersebut.
Service_rating, merupakan data layanan restoran tersebut.
Nah, untuk melihat distribusi rating pada data, gunakan fungsi describe() dengan menerapkan kode berikut:
"""

rating.head()

rating.describe()

"""Dari output di atas, diketahui bahwa nilai maksimum rating adalah 2 dan nilai minimumnya adalah 0. Artinya, skala rating berkisar antara 0 hingga 2.

Untuk melihat berapa pengguna yang memberikan rating, jumlah restoran, dan jumlah rating, jalankan kode berikut.
"""

print('Jumlah userID: ', len(rating.userID.unique()))
print('Jumlah placeID: ', len(rating.placeID.unique()))
print('Jumlah data rating: ', len(rating))

"""Sampai di tahap ini, kita telah memahami variabel-variabel pada data yang kita miliki. Jika Anda ingin mengeksplorasi 5 variabel lainnya (dari 9 variabel yang ada), jangan sungkan untuk mencobanya, ya!

Sekarang, mari kita gabungkan dataset agar dapat diproses untuk membuat sistem rekomendasi.

# Data Preprocessing

Menggabungkan Restoran

Pertama, mari kita identifikasi berapa jumlah seluruh restoran pada dataset. Di sini, kita menggunakan library numpy dan fungsi concatenate untuk menggabungkan beberapa file. Pada materi sebelumnya, Anda mengetahui bahwa kesembilan file data kita dibagi ke dalam tiga kategori, yaitu: Restaurant, User, dan Rating. Nah, pada tahap ini, kita akan menggabungkan seluruh data pada kategori Restaurant. Sehingga, kita akan menggunakan placeID yang unik sebagai acuan dalam penggabungan ini. Implementasikan kode berikut.
"""

import numpy as np

# Menggabungkan seluruh placeID pada kategori Restaurant
resto_all = np.concatenate((
    accepts.placeID.unique(),
    cuisine.placeID.unique(),
    hours.placeID.unique(),
    parking.placeID.unique(),
    geo.placeID.unique()
))

# Mengurutkan data dan menghapus data yang sama
resto_all = np.sort(np.unique(resto_all))

print('Jumlah seluruh data restoran berdasarkan placeID: ', len(resto_all))

"""Output:

Jumlah seluruh data restoran berdasarkan placeID:  938
Perhatikanlah, setelah file pada kategori Restaurant digabung, kita memiliki 938 restoran yang unik.

Menggabungkan Seluruh User

Mari terapkan cara yang sama pada kategori variabel User. Dengan fungsi concatenate dari library numpy, gabungkan seluruh data pada kategori variabel User. Implementasikan kode berikut:

Mengetahui Jumlah Rating

Untuk mengetahui jumlah seluruh rating dari berbagai file, implementasikan kode berikut.
"""

# Menggabungkan seluruh userID
user_all = np.concatenate((
    usercuisine.userID.unique(),
    payment.userID.unique(),
    profile.userID.unique()
))

# Menghapus data yang sama kemudian mengurutkannya
user_all = np.sort(np.unique(user_all))

print('Jumlah seluruh user: ', len(user_all))

"""Output:

Jumlah seluruh user:  138
Menurut Anda, apa yang menarik dari sini? Kita hanya memiliki 138 data pengguna dari 938 restoran yang memiliki rating.

"""

# Menggabungkan file accepts, geo, parking, hours ke dalam dataframe resto_info
resto_info = pd.concat([accepts, geo, parking, hours])

# Menggabungkan dataframe rating dengan resto_info berdasarkan nilai placeID
resto = pd.merge(rating, resto_info , on='placeID', how='left')
resto

"""Variabel setelah dilakukan merge sangat banyak. Output di atas hanya menampilkan sebagian variabel saja. Perhatikanlah, kita memiliki banyak sekali missing value di sini. Mari kita cek lebih lanjut dengan kode berikut.

"""

# Cek missing value dengan fungsi isnull()
resto.isnull().sum()

"""Terdapat banyak missing value pada sebagian besar fitur. Hanya fitur userID, placeID, rating, food_rating, dan service_rating saja yang memiliki 0 missing value. Selanjutnya, mari kita hitung jumlah rating, food_rating, dan service rating berdasarkan place.ID dengan kode berikut."""

# Menghitung jumlah rating, food_rating, dan service kemudian menggabungkannya berdasarkan placeID
resto.groupby('placeID').sum()

"""Menggabungkan Data dengan Fitur Nama Resto

Pertama, definisikan variabel all_resto_rate dengan variabel rating yang telah kita ketahui sebelumnya. Jalankan kode berikut.
"""

# Definisikan dataframe rating ke dalam variabel all_resto_rate
all_resto_rate = rating
all_resto_rate

"""Selanjutnya, untuk mengetahui nama restoran dengan placeID tertentu, mari kita gabungkan data geo yang berisikan placeID dan nama resto berdasarkan placeID dan assign ke variabel all_resto_name dengan fungsi merge dari library pandas."""

# Menggabungkan all resto_rate dengan dataframe geo berdasarkan placeID
all_resto_name = pd.merge(all_resto_rate, geo[['placeID','name']], on='placeID', how='left')

# Print dataframe all_resto_name
all_resto_name

"""Menggabungkan Data dengan Fitur masakan Resto

Langkah selanjutnya adalah menggabungkan variabel all_resto_name yang kita peroleh dari tahapan sebelumnya dengan fitur masakan resto (cuisine). Tujuannya, agar kita mengetahui masakan yang disediakan oleh restoran. Implementasikan kode berikut.
"""

# Menggabungkan dataframe cuisine dengan all_resto_name dan memasukkannya ke dalam variabel all_resto
all_resto = pd.merge(all_resto_name, cuisine, on='placeID', how='left')
all_resto

"""Inilah data yang akan kita gunakan untuk membuat sistem rekomendasi. Berikutnya, mari kita menuju tahapan Data Preparation.

# Data Preparation

Mengatasi Missing Value

Setelah proses penggabungan, mari kita cek lagi datanya apakah ada missing value atau tidak. Jalankan kode berikut.
"""

# Mengecek missing value pada dataframe all_resto
all_resto.isnull().sum()

"""Perhatikanlah, terdapat 288 missing value pada fitur ‘Rcuisine’ (kategori masakan). 288 dari 1331 merupakan jumlah yang signifikan. Sebenarnya sayang jika data missing value ini langsung di-drop begitu saja. Namun, kita tidak bisa mengidentifikasi nama masakan yang tidak memiliki data ‘Rcuisine’ ini termasuk ke dalam kategori masakan mana. Oleh karena itu, untuk saat ini kita akan drop saja missing value ini."""

# Membersihkan missing value dengan fungsi dropna()
all_resto_clean = all_resto.dropna()
all_resto_clean

"""Perhatikanlah, data kita sekarang memiliki 1043 baris. Untuk memastikan tidak ada missing value lagi dalam data, jalankan kode berikut."""

# Mengecek kembali missing value pada variabel all_resto_clean
all_resto_clean.isnull().sum()

"""OK, sekarang data kita sudah bersih. Mari lanjutkan ke tahap berikutnya!

Menyamakan Jenis masakan

Sebelum masuk tahap akhir (pemodelan), kita perlu menyamakan nama masakan. Kadang, masakan yang sama memiliki nama atau kategori yang berbeda. Jika dibiarkan, hal ini bisa menyebabkan bias pada data. Sebagai contoh, pada data yang digunakan dalam studi kasus ini, Anda akan menemukan nama masakan ‘Game’. Anda tentu bertanya-tanya, jenis makanan apa ini? Nah, Anda akan menemukan jawabannya pada tahapan ini.  

Pertama, mari kita cek ulang data setelah proses cleaning pada tahap sebelumnya. Kita buat variabel baru bernama fix_resto untuk menyimpan dataframe.
"""

# Mengurutkan resto berdasarkan PlaceID kemudian memasukkannya ke dalam variabel fix_resto
fix_resto = all_resto_clean.sort_values('placeID', ascending=True)
fix_resto

"""Sekarang, kita memiliki 1043 baris data. Untuk mengecek berapa jumlah restoran yang mencakup data tersebut, jalankan kode berikut"""

# Mengecek berapa jumlah fix_resto
len(fix_resto.placeID.unique())

"""Output:

95
Selanjutnya, mari kita cek Rcuisine (kategori masakan) yang unik dengan kode berikut.
"""

# Mengecek kategori masakan yang unik
fix_resto.Rcuisine.unique()

"""Perhatikanlah, di antara semua kategori masakan pada data, ada satu yang menarik, yaitu kategori masakan bernama ‘Game’. Hal-hal seperti ini kadang kita temukan pada data. Penyebabnya bisa beragam, misalnya, kesalahan input data atau perbedaan istilah di suatu daerah dengan daerah lainnya. Jika menemukan data seperti ini, hal yang perlu kita lakukan adalah mengeksplorasi datanya lebih lanjut dan melakukan analisis.

Dari proses analisis, kita akan memahami perbedaan penamaan ini terjadi pada data mana saja dan apa yang bisa kita lakukan untuk mengatasinya. Tentu solusi untuk permasalahan seperti ini akan berbeda tergantung kasusnya. Untuk kasus pada proyek ini, kita akan memilih salah satu penamaan kategori saja untuk digunakan pada data.

Nah, Anda tentu penasaran, restoran mana yang memiliki kategori ‘Game’? Mari kita lihat sama-sama.
"""

# Mengecek kategori masakan Game
fix_resto[fix_resto['Rcuisine'] == 'Game']

"""Ternyata, Game adalah masakan pada nama restoran KFC. Menarik. Pertanyaan selanjutnya, adakah kategori masakan (Rcuisine) lain untuk KFC? Mari kita cek."""

# Mengecek kategori masakan pada nama restoran KFC
fix_resto[fix_resto['name'] == 'KFC']

"""Ada! Ternyata, KFC memiliki dua kategori masakan yang berbeda, ‘Game’ dan ‘American’. Tentu ini harus diperbaiki. Dalam sistem rekomendasi yang akan kita kembangkan, satu restoran memiliki satu kategori masakan. Dalam hal ini, KFC lebih cocok disebut sebagai restoran dengan kategori masakan American. Jadi, kita perlu mengganti kategori ‘Game’ dengan ‘American’.

Jalankan kode berikut.
"""

# Mengubah nama kategori masakan ‘Game’ menjadi ‘American’
fix_resto = fix_resto.replace('Game', 'American')
fix_resto[fix_resto['name'] == 'KFC']

"""Bagus! Sekarang, semua kategori masakan ‘Game’ telah berubah menjadi ‘American’. Kini, restoran ‘KFC’ telah memiliki satu kategori masakan seperti yang kita harapkan, yaitu ‘American’. Dalam sistem rekomendasi yang kita kembangkan, penting untuk memastikan satu restoran mewakili satu kategori masakan. Tujuannya supaya tidak terjadi dobel atau rangkap kategori dalam satu restoran. Sehingga, sistem dapat merekomendasikan resto berdasarkan kategori masakannya.

Berikutnya, kita bisa melanjutkan ke tahap persiapan. Buatlah variabel bernama preparation. Jalankan kode berikut.
"""

# Membuat variabel preparation yang berisi dataframe fix_resto kemudian mengurutkan berdasarkan placeID
preparation = fix_resto
preparation.sort_values('placeID')

"""Selanjutnya, kita hanya akan menggunakan data unik untuk dimasukkan ke dalam proses pemodelan. Oleh karena itu, kita perlu menghapus data yang duplikat dengan fungsi drop_duplicates(). Dalam hal ini, kita membuang data duplikat pada kolom ‘placeID’. Implementasikan kode berikut."""

# Membuang data duplikat pada variabel preparation
preparation = preparation.drop_duplicates('placeID')
preparation

"""Selanjutnya, kita perlu melakukan konversi data series menjadi list. Dalam hal ini, kita menggunakan fungsi tolist() dari library numpy. Implementasikan kode berikut."""

# Mengonversi data series ‘placeID’ menjadi dalam bentuk list
resto_id = preparation['placeID'].tolist()

# Mengonversi data series ‘Name’ menjadi dalam bentuk list
resto_name = preparation['name'].tolist()

# Mengonversi data series ‘Rcuisine’ menjadi dalam bentuk list
resto_cuisine = preparation['Rcuisine'].tolist()

print(len(resto_id))
print(len(resto_name))
print(len(resto_cuisine))

"""Tahap berikutnya, kita akan membuat dictionary untuk menentukan pasangan key-value pada data resto_id, resto_name, dan resto_cuisine yang telah kita siapkan sebelumnya"""

# Membuat dictionary untuk data ‘resto_id’, ‘resto_name’, dan ‘cuisine’
resto_new = pd.DataFrame({
    'id': resto_id,
    'resto_name': resto_name,
    'cuisine': resto_cuisine
})
resto_new

"""# Model Development dengan Content Based Filtering
Sampai di sini, Anda telah melewati serangkaian tahapan untuk membuat sistem rekomendasi mulai dari:

Data Understanding.
Univariate Exploratory Data Analysis.
Data Preprocessing.
Data Preparation.
Kini, saatnya Anda mengembangkan sistem rekomendasi dengan pendekatan content based filtering. Tapi sebelumnya, mari cek lagi data yang kita miliki dan assign dataframe dari tahap sebelumnya ke dalam variabel data, sebagai berikut:
"""

data = resto_new
data.sample(5)

"""**TF-IDF Vectorizer**

Pada tahap ini, kita akan membangun sistem rekomendasi sederhana berdasarkan jenis masakan yang disediakan restoran. Anda telah belajar mengenai TF-IDF Vectorizer pada modul Sentiment Analysis. Teknik tersebut juga akan digunakan pada sistem rekomendasi untuk menemukan representasi fitur penting dari setiap kategori masakan.

Sama seperti proyek sentiment analysis, pada proyek ini, kita juga menggunakan fungsi tfidfvectorizer() dari library sklearn. Jalankan kode berikut
"""

from sklearn.feature_extraction.text import TfidfVectorizer

# Inisialisasi TfidfVectorizer
tf = TfidfVectorizer()

# Melakukan perhitungan idf pada data cuisine
tf.fit(data['cuisine'])

# Mapping array dari fitur index integer ke fitur nama
tf.get_feature_names_out()

"""Selanjutnya, lakukan fit dan transformasi ke dalam bentuk matriks."""

# Melakukan fit lalu ditransformasikan ke bentuk matrix
tfidf_matrix = tf.fit_transform(data['cuisine'])

# Melihat ukuran matrix tfidf
tfidf_matrix.shape

"""Perhatikanlah, matriks yang kita miliki berukuran (95, 22). Nilai 95 merupakan ukuran data dan 22 merupakan matrik kategori masakan.

Untuk menghasilkan vektor tf-idf dalam bentuk matriks, kita menggunakan fungsi todense(). Jalankan kode berikut.
"""

# Mengubah vektor tf-idf dalam bentuk matriks dengan fungsi todense()
tfidf_matrix.todense()

"""Selanjutnya, mari kita lihat matriks tf-idf untuk beberapa resto (resto_name) dan kategori masakan (cuisine). Terapkan kode berikut"""

# Membuat dataframe untuk melihat tf-idf matrix
# Kolom diisi dengan jenis masakan
# Baris diisi dengan nama resto

pd.DataFrame(
    tfidf_matrix.todense(),
    columns=tf.get_feature_names_out(),
    index=data.resto_name
).sample(22, axis=1).sample(10, axis=0)

"""Output matriks tf-idf di atas menunjukkan Restaurant Bar Fu-hao memiliki kategori bar. Bar Fu-hao, matriks menunjukan bahwa restoran tersebut merupakan resto dengan kategori bar. Hal ini terlihat dari nilai matriks 1.0 pada kategori bar. Selanjutnya, restoran El Rincon de San Francisco termasuk dalam kategori mexican. Sedangkan, restoran Tortas y hamburguesas el gordo termasuk dalam kategori burgers. Demikian seterusnya.

Sampai di sini, kita telah berhasil mengidentifikasi representasi fitur penting dari setiap kategori masakan dengan fungsi tfidfvectorizer. Kita juga telah menghasilkan matriks yang menunjukkan korelasi antara jenis masakan dengan restoran. Selanjutnya, kita akan menghitung derajat kesamaan antara satu restoran dengan restoran lainnya untuk menghasilkan kandidat restoran yang akan direkomendasikan.

**Cosine Similarity**

Pada tahap sebelumnya, kita telah berhasil mengidentifikasi korelasi antara restoran dengan kategori masakannya. Sekarang, kita akan menghitung derajat kesamaan (similarity degree) antar restoran dengan teknik cosine similarity. Di sini, kita menggunakan fungsi cosine_similarity dari library sklearn.

Jalankan kode berikut.
"""

from sklearn.metrics.pairwise import cosine_similarity

# Menghitung cosine similarity pada matrix tf-idf
cosine_sim = cosine_similarity(tfidf_matrix)
cosine_sim

"""Pada tahapan ini, kita menghitung cosine similarity dataframe tfidf_matrix yang kita peroleh pada tahapan sebelumnya. Dengan satu baris kode untuk memanggil fungsi cosine similarity dari library sklearn, kita telah berhasil menghitung kesamaan (similarity) antar restoran. Kode di atas menghasilkan keluaran berupa matriks kesamaan dalam bentuk array.

Selanjutnya, mari kita lihat matriks kesamaan setiap resto dengan menampilkan nama restoran dalam 5 sampel kolom (axis = 1) dan 10 sampel baris (axis=0). Jalankan kode berikut.
"""

# Membuat dataframe dari variabel cosine_sim dengan baris dan kolom berupa nama resto
cosine_sim_df = pd.DataFrame(cosine_sim, index=data['resto_name'], columns=data['resto_name'])
print('Shape:', cosine_sim_df.shape)

# Melihat similarity matrix pada setiap resto
cosine_sim_df.sample(5, axis=1).sample(10, axis=0)

"""Dengan cosine similarity, kita berhasil mengidentifikasi kesamaan antara satu restoran dengan restoran lainnya. Shape (95, 95) merupakan ukuran matriks similarity dari data yang kita miliki. Berdasarkan data yang ada, matriks di atas sebenarnya berukuran 95 restoran x 95 restoran (masing-masing dalam sumbu X dan Y). Artinya, kita mengidentifikasi tingkat kesamaan pada 95 nama restoran. Tapi tentu kita tidak bisa menampilkan semuanya. Oleh karena itu, kita hanya memilih 10 restoran pada baris vertikal dan 5 restoran pada sumbu horizontal seperti pada contoh di atas.

Perhatikanlah kotak merah pada output matriks di atas. Angka 1.0 yang diberi kotak merah mengindikasikan bahwa restoran pada kolom X (horizontal) memiliki kesamaan dengan restoran pada baris Y (vertikal). Sebagai contoh, restoran Gorditas Doa Gloria dan Gorditas Dona Tota teridentifikasi sama (similar) dengan restoran Palomo Tec. Contoh lain, restoran La Perica Hamburguesa teridentifikasi mirip dengan restoran El Mundo de La Pasta. Cukup jelas, bukan?

Nah, dengan data kesamaan (similarity) restoran yang diperoleh dari kode sebelumnya, kita akan merekomendasikan daftar resto yang mirip (similar) dengan resto yang sebelumnya pernah melayani pengguna. Yuk lanjut ke materi berikutnya!

**Mendapatkan Rekomendasi**

Sebelumnya, kita telah memiliki data similarity (kesamaan) antar restoran. Kini, tibalah saatnya  menghasilkan sejumlah restoran yang akan direkomendasikan kepada pengguna. Untuk lebih memahami bagaimana cara kerjanya, lihatlah kembali matriks similarity pada tahap sebelumnya. Sebagai gambaran, mari kita ambil satu contoh berikut.

Pengguna X pernah memesan makanan dari resto Palomo Tec. Kemudian, saat pengguna tersebut berencana untuk memesan makanan dari restoran lain, sistem akan merekomendasikan resto Gorditas Doa Gloria atau Gorditas Dona Tota. Nah, rekomendasi kedua restoran ini berdasarkan kesamaan yang dihitung dengan cosine similarity pada tahap sebelumnya.

Di sini, kita membuat fungsi resto_recommendations dengan beberapa parameter sebagai berikut:

Nama_resto : Nama restoran (index kemiripan dataframe).
Similarity_data : Dataframe mengenai similarity yang telah kita definisikan sebelumnya.
Items : Nama dan fitur yang digunakan untuk mendefinisikan kemiripan, dalam hal ini adalah ‘resto_name’ dan ‘cuisine’.
k : Banyak rekomendasi yang ingin diberikan.
Sebelum mulai menulis kodenya, ingatlah kembali definisi sistem rekomendasi yang menyatakan bahwa keluaran sistem ini adalah berupa top-N recommendation. Oleh karena itu, kita akan memberikan sejumlah rekomendasi restoran pada pengguna yang diatur dalam parameter k.

Jalankan kode berikut.
"""

def resto_recommendations(nama_resto, similarity_data=cosine_sim_df, items=data[['resto_name', 'cuisine']], k=5):
    """
    Rekomendasi Resto berdasarkan kemiripan dataframe

    Parameter:
    ---
    nama_resto : tipe data string (str)
                Nama Restoran (index kemiripan dataframe)
    similarity_data : tipe data pd.DataFrame (object)
                      Kesamaan dataframe, simetrik, dengan resto sebagai
                      indeks dan kolom
    items : tipe data pd.DataFrame (object)
            Mengandung kedua nama dan fitur lainnya yang digunakan untuk mendefinisikan kemiripan
    k : tipe data integer (int)
        Banyaknya jumlah rekomendasi yang diberikan
    ---


    Pada index ini, kita mengambil k dengan nilai similarity terbesar
    pada index matrix yang diberikan (i).
    """


    # Mengambil data dengan menggunakan argpartition untuk melakukan partisi secara tidak langsung sepanjang sumbu yang diberikan
    # Dataframe diubah menjadi numpy
    # Range(start, stop, step)
    index = similarity_data.loc[:,nama_resto].to_numpy().argpartition(
        range(-1, -k, -1))

    # Mengambil data dengan similarity terbesar dari index yang ada
    closest = similarity_data.columns[index[-1:-(k+2):-1]]

    # Drop nama_resto agar nama resto yang dicari tidak muncul dalam daftar rekomendasi
    closest = closest.drop(nama_resto, errors='ignore')

    return pd.DataFrame(closest).merge(items).head(k)

"""Perhatikanlah, dengan menggunakan argpartition, kita mengambil sejumlah nilai k tertinggi dari similarity data (dalam kasus ini: dataframe cosine_sim_df). Kemudian, kita mengambil data dari bobot (tingkat kesamaan) tertinggi ke terendah. Data ini dimasukkan ke dalam variabel closest. Berikutnya, kita perlu menghapus nama_resto yang yang dicari agar tidak muncul dalam daftar rekomendasi. Dalam kasus ini, nanti kita akan mencari resto yang mirip dengan KFC, sehingga kita perlu drop nama_resto KFC agar tidak muncul dalam daftar rekomendasi yang diberikan nanti.  

Selanjutnya, mari kita terapkan kode di atas untuk menemukan rekomendasi restoran yang mirip dengan KFC. Terapkan kode berikut:
"""

data[data.resto_name.eq('KFC')]

data[data.resto_name.eq('KFC')]

# Mendapatkan rekomendasi restoran yang mirip dengan KFC
resto_recommendations('KFC')

"""Perhatikanlah, KFC masuk dalam kategori cuisine American. Tentu kita berharap rekomendasi yang diberikan adalah resto dengan kategori yang mirip. Nah, sekarang, dapatkan resto recommendation dengan memanggil fungsi yang telah kita definisikan sebelumnya:"""

# Mendapatkan rekomendasi restoran yang mirip dengan KFC
resto_recommendations('KFC')

"""Yay! Berhasil! Sistem kita memberikan rekomendasi 5 nama restoran dengan kategori ‘cuisine’ American dan satu kategori International. Bagaimana menurut Anda?

# Model Development dengan Collaborative Filtering
Sebelumnya kita telah menerapkan teknik content based filtering pada data. Teknik ini merekomendasikan item yang mirip dengan preferensi pengguna di masa lalu. Pada materi ini, kita akan menerapkan teknik collaborative filtering untuk membuat sistem rekomendasi. Teknik ini membutuhkan data rating dari user.

Goal proyek kita kali ini adalah menghasilkan rekomendasi sejumlah restoran yang sesuai dengan preferensi pengguna berdasarkan rating yang telah diberikan sebelumnya. Dari data rating pengguna, kita akan mengidentifikasi restoran-restoran yang mirip dan belum pernah dikunjungi oleh pengguna untuk direkomendasikan. Kita akan menggunakan teknik collaborative filtering untuk membuat rekomendasi ini.

Yuk, langsung kita bangun model sistemnya!
"""

# Import library
import pandas as pd
import numpy as np
from zipfile import ZipFile
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from pathlib import Path
import matplotlib.pyplot as plt

"""Selanjutnya, pahami terlebih dahulu data rating yang kita miliki. Ingatlah saat Anda melakukan load data di awal dan membaca file rating_final.csv. Saat itu, Anda membuat variabel rating dan menetapkan data pada variabel tersebut. Untuk memudahkan supaya tidak tertukar dengan fitur ‘rating’ pada data, kita ubah nama variabel rating menjadi df."""

# Membaca dataset

df = rating
df

"""Perhatikanlah, data rating memiliki 1161 baris dan 5 kolom.

## **Data Preparation**

Kini Anda memasuki tahap preprocessing. Pada tahap ini, Anda perlu melakukan persiapan data untuk menyandikan (encode) fitur ‘user’ dan ‘placeID’ ke dalam indeks integer. Terapkan kode berikut.
"""

# Mengubah userID menjadi list tanpa nilai yang sama
user_ids = df['userID'].unique().tolist()
print('list userID: ', user_ids)

# Melakukan encoding userID
user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}
print('encoded userID : ', user_to_user_encoded)

# Melakukan proses encoding angka ke ke userID
user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}
print('encoded angka ke userID: ', user_encoded_to_user)

"""Selanjutnya, lakukan hal yang sama pada fitur ‘placeID’."""

# Mengubah placeID menjadi list tanpa nilai yang sama
resto_ids = df['placeID'].unique().tolist()

# Melakukan proses encoding placeID
resto_to_resto_encoded = {x: i for i, x in enumerate(resto_ids)}

# Melakukan proses encoding angka ke placeID
resto_encoded_to_resto = {i: x for i, x in enumerate(resto_ids)}

"""Berikutnya, petakan userID dan placeID ke dataframe yang berkaitan."""

# Mapping userID ke dataframe user
df['user'] = df['userID'].map(user_to_user_encoded)

# Mapping placeID ke dataframe resto
df['resto'] = df['placeID'].map(resto_to_resto_encoded)

"""Terakhir, cek beberapa hal dalam data seperti jumlah user, jumlah resto, dan mengubah nilai rating menjadi float."""

# Mendapatkan jumlah user
num_users = len(user_to_user_encoded)
print(num_users)

# Mendapatkan jumlah resto
num_resto = len(resto_encoded_to_resto)
print(num_resto)

# Mengubah rating menjadi nilai float
df['rating'] = df['rating'].values.astype(np.float32)

# Nilai minimum rating
min_rating = min(df['rating'])

# Nilai maksimal rating
max_rating = max(df['rating'])

print('Number of User: {}, Number of Resto: {}, Min Rating: {}, Max Rating: {}'.format(
    num_users, num_resto, min_rating, max_rating
))

"""Tahap persiapan telah selesai. Berikut adalah hal-hal yang telah kita lakukan pada tahap ini:

Memahami data rating yang kita miliki.
Menyandikan (encode) fitur ‘user’ dan ‘placeID’ ke dalam indeks integer.
Memetakan ‘userID’ dan ‘placeID’ ke dataframe yang berkaitan.
Mengecek beberapa hal dalam data seperti jumlah user, jumlah resto, kemudian mengubah nilai rating menjadi float.
Tahap persiapan ini penting dilakukan agar data siap digunakan untuk pemodelan. Namun sebelumnya, kita perlu membagi data untuk training dan validasi terlebih dahulu yang akan kita pelajari di materi berikutnya. Tunggu apalagi, yuk kita lanjutkan.

**Membagi Data untuk Training dan Validasi**

Anda tentu sudah menduga, pada tahap ini kita akan melakukan pembagian data menjadi data training dan validasi. Betul! Namun sebelumnya, acak datanya terlebih dahulu agar distribusinya menjadi random..
"""

# Mengacak dataset
df = df.sample(frac=1, random_state=42)
df

"""Selanjutnya, kita bagi data train dan validasi dengan komposisi 80:20. Namun sebelumnya, kita perlu memetakan (mapping) data user dan resto menjadi satu value terlebih dahulu. Lalu, buatlah rating dalam skala 0 sampai 1 agar mudah dalam melakukan proses training."""

# Membuat variabel x untuk mencocokkan data user dan resto menjadi satu value
x = df[['user', 'resto']].values

# Membuat variabel y untuk membuat rating dari hasil
y = df['rating'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values

# Membagi menjadi 80% data train dan 20% data validasi
train_indices = int(0.8 * df.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)

print(x, y)

"""Data telah siap untuk dimasukkan ke dalam model. Yuk lanjut ke materi berikutnya!

**Proses Training**
Pada tahap ini, model menghitung skor kecocokan antara pengguna dan resto dengan teknik embedding. Pertama, kita melakukan proses embedding terhadap data user dan resto. Selanjutnya, lakukan operasi perkalian dot product antara embedding user dan resto. Selain itu, kita juga dapat menambahkan bias untuk setiap user dan resto. Skor kecocokan ditetapkan dalam skala [0,1] dengan fungsi aktivasi sigmoid.

Di sini, kita membuat class RecommenderNet dengan keras Model class. Kode class RecommenderNet ini terinspirasi dari tutorial dalam situs Keras dengan beberapa adaptasi sesuai kasus yang sedang kita selesaikan. Terapkan kode berikut.
"""

class RecommenderNet(tf.keras.Model):

  # Insialisasi fungsi
  def __init__(self, num_users, num_resto, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_resto = num_resto
    self.embedding_size = embedding_size
    self.user_embedding = layers.Embedding( # layer embedding user
        num_users,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.user_bias = layers.Embedding(num_users, 1) # layer embedding user bias
    self.resto_embedding = layers.Embedding( # layer embeddings resto
        num_resto,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.resto_bias = layers.Embedding(num_resto, 1) # layer embedding resto bias

  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:,0]) # memanggil layer embedding 1
    user_bias = self.user_bias(inputs[:, 0]) # memanggil layer embedding 2
    resto_vector = self.resto_embedding(inputs[:, 1]) # memanggil layer embedding 3
    resto_bias = self.resto_bias(inputs[:, 1]) # memanggil layer embedding 4

    dot_user_resto = tf.tensordot(user_vector, resto_vector, 2)

    x = dot_user_resto + user_bias + resto_bias

    return tf.nn.sigmoid(x) # activation sigmoid

"""Selanjutnya, lakukan proses compile terhadap model."""

model = RecommenderNet(num_users, num_resto, 50) # inisialisasi model

# model compile
model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

"""Model ini menggunakan Binary Crossentropy untuk menghitung loss function, Adam (Adaptive Moment Estimation) sebagai optimizer, dan root mean squared error (RMSE) sebagai metrics evaluation.

Langkah berikutnya, mulailah proses training.
"""

# Memulai training

history = model.fit(
    x = x_train,
    y = y_train,
    batch_size = 8,
    epochs = 100,
    validation_data = (x_val, y_val)
)

"""**Visualisasi Metrik**

Untuk melihat visualisasi proses training, mari kita plot metrik evaluasi dengan matplotlib. Terapkan kode berikut.
"""

plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('model_metrics')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""Perhatikanlah, proses training model cukup smooth dan model konvergen pada epochs sekitar 100. Dari proses ini, kita memperoleh nilai error akhir sebesar sekitar 0.23 dan error pada data validasi sebesar 0.34. Nilai tersebut cukup bagus untuk sistem rekomendasi. Mari kita cek, apakah model ini bisa membuat rekomendasi dengan baik?

**Mendapatkan Rekomendasi Resto**

Untuk mendapatkan rekomendasi resto, pertama kita ambil sampel user secara acak dan definisikan variabel resto_not_visited yang merupakan daftar resto yang belum pernah dikunjungi oleh pengguna. Anda mungkin bertanya-tanya, mengapa kita perlu menentukan daftar resto_not_visited? Hal ini karena daftar resto_not_visited inilah yang akan menjadi resto yang kita rekomendasikan.

Sebelumnya, pengguna telah memberi rating pada beberapa resto yang telah mereka kunjungi. Kita menggunakan rating ini untuk membuat rekomendasi restoran yang mungkin cocok untuk pengguna. Nah, restoran yang akan direkomendasikan tentulah restoran yang belum pernah dikunjungi oleh pengguna. Oleh karena itu, kita perlu membuat variabel resto_not_visited sebagai daftar restoran untuk direkomendasikan pada pengguna.

Variabel resto_not_visited diperoleh dengan menggunakan operator bitwise (~) pada variabel resto_visited_by_user.

Terapkan kode berikut.
"""

resto_df = resto_new
df = pd.read_csv('rating_final.csv')

# Mengambil sample user
user_id = df.userID.sample(1).iloc[0]
resto_visited_by_user = df[df.userID == user_id]

# Operator bitwise (~), bisa diketahui di sini https://docs.python.org/3/reference/expressions.html
resto_not_visited = resto_df[~resto_df['id'].isin(resto_visited_by_user.placeID.values)]['id']
resto_not_visited = list(
    set(resto_not_visited)
    .intersection(set(resto_to_resto_encoded.keys()))
)

resto_not_visited = [[resto_to_resto_encoded.get(x)] for x in resto_not_visited]
user_encoder = user_to_user_encoded.get(user_id)
user_resto_array = np.hstack(
    ([[user_encoder]] * len(resto_not_visited), resto_not_visited)
)

"""Selanjutnya, untuk memperoleh rekomendasi restoran, gunakan fungsi model.predict() dari library Keras dengan menerapkan kode berikut."""

ratings = model.predict(user_resto_array).flatten()

top_ratings_indices = ratings.argsort()[-10:][::-1]
recommended_resto_ids = [
    resto_encoded_to_resto.get(resto_not_visited[x][0]) for x in top_ratings_indices
]

print('Showing recommendations for users: {}'.format(user_id))
print('===' * 9)
print('Resto with high ratings from user')
print('----' * 8)

top_resto_user = (
    resto_visited_by_user.sort_values(
        by = 'rating',
        ascending=False
    )
    .head(5)
    .placeID.values
)

resto_df_rows = resto_df[resto_df['id'].isin(top_resto_user)]
for row in resto_df_rows.itertuples():
    print(row.resto_name, ':', row.cuisine)

print('----' * 8)
print('Top 10 resto recommendation')
print('----' * 8)

recommended_resto = resto_df[resto_df['id'].isin(recommended_resto_ids)]
for row in recommended_resto.itertuples():
    print(row.resto_name, ':', row.cuisine)

"""Selamat! Anda telah berhasil memberikan rekomendasi kepada user. Sebagai contoh, hasil di atas adalah rekomendasi untuk user dengan id U1071. Dari output tersebut, kita dapat membandingkan antara Resto with high ratings from user dan Top 10 resto recommendation untuk user.

Perhatikanlah, beberapa restoran rekomendasi menyediakan kategori masakan (cuisine) yang sesuai dengan rating user. Kita memperoleh 4 rekomendasi resto dengan kategori ‘cuisine’ Mexican, 2 rekomendasi resto dengan kategori bar, dan 1 resto dengan kategori International.

Prediksinya cukup sesuai, bukan?

Sampai di tahap ini, Anda telah berhasil membuat sistem rekomendasi dengan dua teknik, yaitu Content based Filtering dan Collaborative Filtering. Sistem rekomendasi yang Anda buat telah berhasil memberikan sejumlah rekomendasi restoran yang sesuai dengan preferensi pengguna.

Ingatlah, setiap teknik membutuhkan data yang berbeda dan bekerja dengan cara yang berbeda pula. Misalnya, pada teknik collaborative filtering, Anda membutuhkan data rating dari pengguna. Sedangkan, pada content based filtering, data rating tidak diperlukan.

Jika Anda masih penasaran untuk mencoba membuat sistem rekomendasi dengan data lain atau teknik lain, jangan ragu untuk mencoba, ya!
"""

!pip freeze requirements.txt